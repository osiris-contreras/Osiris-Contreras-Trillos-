{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelo de Shallow Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "por: \n",
        "     Juan José Molina Ocampo  \n",
        "     Gloria Maritza Zapata González   \n",
        "     Osiris Contreras Trillos  \n",
        "     David Stiveen Tamayo Toro  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgAaLlVcZLft",
        "outputId": "0f1b62bb-c199-4fc8-807a-5b22a1e1cceb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WEUch4LcLRC2Upnfg-hnT4pPymov-SFn\n",
            "To: c:\\Users\\osiri\\Desktop\\datasets\\first_dataset.zip\n",
            "100%|██████████| 16.3M/16.3M [00:00<00:00, 19.8MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=17c_1I3rrUovfYVDYxn7zkWtCR8Gz62sc\n",
            "From (redirected): https://drive.google.com/uc?id=17c_1I3rrUovfYVDYxn7zkWtCR8Gz62sc&confirm=t&uuid=e92b3173-d877-47db-a2cf-5ebfc9eeeebe\n",
            "To: c:\\Users\\osiri\\Desktop\\datasets\\second_dataset.zip\n",
            "100%|██████████| 42.9M/42.9M [00:01<00:00, 24.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UmoHB1vGfiQ-F-HcGPCp96-hAahA2_89\n",
            "To: c:\\Users\\osiri\\Desktop\\datasets\\third_dataset.zip\n",
            "100%|██████████| 23.5M/23.5M [00:00<00:00, 26.2MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1djsKtT1CVEZhWNeIR2MrLWE_3jqWDUfy\n",
            "From (redirected): https://drive.google.com/uc?id=1djsKtT1CVEZhWNeIR2MrLWE_3jqWDUfy&confirm=t&uuid=c18eaa8e-4fa1-4ceb-8fa2-88418ffb6819\n",
            "To: c:\\Users\\osiri\\Desktop\\datasets\\fourth_dataset.zip\n",
            "100%|██████████| 93.7M/93.7M [00:02<00:00, 36.6MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Los datasets han sido combinados en ./combined_dataset/.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import gdown\n",
        "\n",
        "# Directorio de destino para guardar los datasets\n",
        "output_dir = './datasets/'\n",
        "\n",
        "# Crea el directorio si no existe\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Función para descargar y extraer archivos comprimidos\n",
        "def extract_zip(file_path, output_dir):\n",
        "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(output_dir)\n",
        "\n",
        "# Función para descargar archivos de Google Drive\n",
        "def download_from_gdrive(file_id, dest_path):\n",
        "    url = f'https://drive.google.com/uc?id={file_id}'\n",
        "    gdown.download(url, dest_path, quiet=False)\n",
        "\n",
        "# Descarga y extrae el primer archivo comprimido\n",
        "download_from_gdrive('1WEUch4LcLRC2Upnfg-hnT4pPymov-SFn', os.path.join(output_dir, 'first_dataset.zip'))\n",
        "extract_zip(os.path.join(output_dir, 'first_dataset.zip'), output_dir)\n",
        "\n",
        "# Descarga y extrae el segundo archivo comprimido\n",
        "download_from_gdrive('17c_1I3rrUovfYVDYxn7zkWtCR8Gz62sc', os.path.join(output_dir, 'second_dataset.zip'))\n",
        "extract_zip(os.path.join(output_dir, 'second_dataset.zip'), output_dir)\n",
        "\n",
        "# Descarga y extrae el tercer archivo comprimido\n",
        "download_from_gdrive('1UmoHB1vGfiQ-F-HcGPCp96-hAahA2_89', os.path.join(output_dir, 'third_dataset.zip'))\n",
        "extract_zip(os.path.join(output_dir, 'third_dataset.zip'), output_dir)\n",
        "\n",
        "# Descarga y extrae el cuarto archivo comprimido\n",
        "download_from_gdrive('1djsKtT1CVEZhWNeIR2MrLWE_3jqWDUfy', os.path.join(output_dir, 'fourth_dataset.zip'))\n",
        "extract_zip(os.path.join(output_dir, 'fourth_dataset.zip'), output_dir)\n",
        "\n",
        "# Directorio donde descomprimir los archivos combinados\n",
        "combined_dir = './combined_dataset/'\n",
        "\n",
        "# Crear el directorio de combinación si no existe\n",
        "os.makedirs(combined_dir, exist_ok=True)\n",
        "\n",
        "# Función para combinar los datasets en un solo directorio\n",
        "def combine_datasets(input_dir, output_dir):\n",
        "    for root, dirs, files in os.walk(input_dir):\n",
        "        for file in files:\n",
        "            shutil.copy(os.path.join(root, file), output_dir)\n",
        "\n",
        "# Combina los datasets en un solo directorio\n",
        "combine_datasets(output_dir, combined_dir)\n",
        "\n",
        "print(f\"Los datasets han sido combinados en {combined_dir}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Limpieza y transformación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piQFqrUiaupc",
        "outputId": "23eafd22-8af2-4d7f-b10d-25385916667f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se eliminaron las siguientes imágenes dañadas:\n",
            "entero_grano3352.png\n",
            "first_dataset.zip\n",
            "fourth_dataset.zip\n",
            "second_dataset.zip\n",
            "third_dataset.zip\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image, UnidentifiedImageError\n",
        "\n",
        "def remove_corrupted_images(combined_dir):\n",
        "    removed_images = []\n",
        "    for filename in os.listdir(combined_dir):\n",
        "        file_path = os.path.join(combined_dir, filename)\n",
        "        try:\n",
        "            img = Image.open(file_path)\n",
        "            img.verify()  # Verifica si la imagen está dañada\n",
        "            if img.size[0] == 0 or img.size[1] == 0:\n",
        "                os.remove(file_path)  # Elimina la imagen vacía\n",
        "                removed_images.append(filename)\n",
        "        except (IOError, SyntaxError, UnidentifiedImageError):\n",
        "            os.remove(file_path)  # Elimina la imagen dañada\n",
        "            removed_images.append(filename)\n",
        "        except Exception as e:\n",
        "            print(f\"Error al procesar {filename}: {str(e)}\")\n",
        "\n",
        "    return removed_images\n",
        "\n",
        "removed_images = remove_corrupted_images(combined_dir)\n",
        "\n",
        "if removed_images:\n",
        "    print(\"Se eliminaron las siguientes imágenes dañadas:\")\n",
        "    for filename in removed_images:\n",
        "        print(filename)\n",
        "else:\n",
        "    print(\"No se encontraron imágenes dañadas.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jp6B1kjed9vW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Crear un DataFrame de etiquetas asumiendo que ya has cargado los labels desde los nombres de archivos\n",
        "image_files = [f for f in os.listdir(combined_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# Crear una lista de diccionarios para almacenar los datos\n",
        "data = []\n",
        "for image_file in image_files:\n",
        "    label = image_file.split('_')[0]  # Extraer la etiqueta del nombre del archivo\n",
        "    data.append({'filename': image_file, 'label': label})\n",
        "\n",
        "# Convertir la lista de diccionarios a un DataFrame de pandas\n",
        "labels_df = pd.DataFrame(data)\n",
        "labels_csv = '/content/combined_dataset/labels.csv'\n",
        "labels_df.to_csv(labels_csv, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DKd1c0deAd9",
        "outputId": "5c2fa421-33e9-41b0-a9c0-c070ef8da3ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesado lote 1 de 7\n",
            "Procesado lote 2 de 7\n",
            "Procesado lote 3 de 7\n",
            "Procesado lote 4 de 7\n",
            "Procesado lote 5 de 7\n",
            "Procesado lote 6 de 7\n",
            "Procesado lote 7 de 7\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Tamaño de las imágenes (deben coincidir con las dimensiones usadas en la redimension)\n",
        "image_size = (100, 100)\n",
        "\n",
        "# Crear arrays para las imágenes y etiquetas\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Cargar y preprocesar imágenes por lotes\n",
        "batch_size = 1000\n",
        "num_batches = len(labels_df) // batch_size + 1\n",
        "\n",
        "def load_and_preprocess_image(filepath):\n",
        "    try:\n",
        "        img = load_img(filepath, target_size=image_size)\n",
        "        img_array = img_to_array(img)\n",
        "        img_array /= 255.0  # Normalizar los valores de píxeles a [0, 1]\n",
        "        return img_array\n",
        "    except UnidentifiedImageError:\n",
        "        print(f\"No se pudo identificar la imagen en {filepath}\")\n",
        "        return None\n",
        "\n",
        "for batch in range(num_batches):\n",
        "    start_idx = batch * batch_size\n",
        "    end_idx = min((batch + 1) * batch_size, len(labels_df))\n",
        "    batch_df = labels_df.iloc[start_idx:end_idx]\n",
        "\n",
        "    for index, row in batch_df.iterrows():\n",
        "        file_path = os.path.join(combined_dir, row['filename'])\n",
        "        img_array = load_and_preprocess_image(file_path)\n",
        "        if img_array is not None:  # Solo agregar si la imagen se cargó correctamente\n",
        "            images.append(img_array)\n",
        "            labels.append(row['label'])\n",
        "\n",
        "    print(f\"Procesado lote {batch + 1} de {num_batches}\")\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Codificar etiquetas\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "juCnohmleIJ9",
        "outputId": "759bfa01-1e43-48c0-ab6e-e9d7a501c3d4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir el dataset en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Aplanar las imágenes para que puedan ser usadas por el SVM\n",
        "# Las imágenes tienen forma (100, 100, 3) y las convertimos a (100*100*3,)\n",
        "X_train_flatten = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flatten = X_test.reshape(X_test.shape[0], -1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelo 5 Máquina de Soporte vectorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kT-vLX93eXPe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;svc&#x27;, SVC(kernel=&#x27;linear&#x27;, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
              "                (&#x27;svc&#x27;, SVC(kernel=&#x27;linear&#x27;, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('svc', SVC(kernel='linear', random_state=42))])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Crear un pipeline que incluya el escalado de características y el SVM\n",
        "svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear', random_state=42))\n",
        "\n",
        "# Entrenar el modelo SVM\n",
        "svm_model.fit(X_train_flatten, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YV11bOjxeap9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6924242424242424\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      entero       0.73      0.72      0.72       684\n",
            "      mancha       0.86      0.84      0.85       171\n",
            "    quebrado       0.82      0.85      0.84       159\n",
            "        tiza       0.46      0.48      0.47       306\n",
            "\n",
            "    accuracy                           0.69      1320\n",
            "   macro avg       0.72      0.72      0.72      1320\n",
            "weighted avg       0.70      0.69      0.69      1320\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = svm_model.predict(X_test_flatten)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparación de resultados con el mejor modelo de redes neuronales, el modelo 4 (convolucional).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Precisión Global: La red neuronal convolucional (modelo 4) tiene una precisión global del 78.64%, que es significativamente mayor que la precisión del modelo SVM (69.24%).\n",
        "* Desempeño por Clase: Para las clases \"Entero\" y \"Quebrado\", ambos modelos tienen un desempeño relativamente similar, aunque la red neuronal convolucional muestra una ligera ventaja en el recall y F1-score.\n",
        "Para la clase \"Mancha\", la red neuronal convolucional tiene una precisión notablemente mayor (0.98) comparada con el SVM (0.86). Sin embargo, el recall del modelo SVM es superior (0.84 vs. 0.73).\n",
        "Para la clase \"Tiza\", ambos modelos tienen un desempeño bajo, pero el modelo SVM muestra una ligera mejora en recall y F1-score comparado con la red neuronal.\n",
        "* Macro y Weighted Averages: La red neuronal convolucional tiene mejores macro y weighted averages en precisión, recall y F1-score, lo que sugiere que, en promedio, maneja mejor la clasificación de todas las clases en comparación con el modelo SVM.\n",
        "\n",
        "Mejor modelo: La red neuronal convolucional (modelo 4) demuestra un rendimiento superior en comparación con el modelo SVM (modelo 5), especialmente en términos de precisión global y en el manejo de clases complejas como \"Mancha\". El mejor desempeño del modelo de red neuronal puede atribuirse a su capacidad de capturar características más complejas y patrones de las imágenes debido a las capas convolucionales y de pooling, que no son posibles de capturar con un modelo SVM lineal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El caso de estudio se centró en la clasificación de imágenes de arroz en cuatro categorías utilizando varios modelos de aprendizaje automático y redes neuronales. Se evaluaron y compararon cinco modelos diferentes para determinar el más efectivo en términos de precisión y rendimiento general.\n",
        "\n",
        "El estudio concluye que las redes neuronales convolucionales son la mejor opción para la clasificación de imágenes de arroz, proporcionando un rendimiento significativamente mejor en comparación con las redes feedforward y los modelos de aprendizaje automático tradicionales como el SVM. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
